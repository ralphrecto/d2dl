{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralph/.venvs/d2dl/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from itertools import product, chain\n",
    "import importlib\n",
    "\n",
    "import trainer, data, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/Users/ralph/projects/d2dl/models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(trainer)\n",
    "importlib.reload(data)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_housing_dataset = data.kaggle_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Sequential):\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_bias_mean,\n",
    "            output_bias_stddev,\n",
    "            hidden_dim: int = 100,\n",
    "            num_outputs: int = 1,\n",
    "        ):\n",
    "        super().__init__(\n",
    "            nn.LazyLinear(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_outputs)\n",
    "        )\n",
    "\n",
    "        nn.init.normal_(\n",
    "            self[-1].bias, \n",
    "            mean=output_bias_mean,\n",
    "            std=1.0\n",
    "        ) \n",
    "\n",
    "    def forward_scaled(self, input):\n",
    "        return torch.exp(self(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = lambda hyperparams: trainer.Trainer(\n",
    "    model=LinearRegression(\n",
    "        output_bias_mean=hyperparams.model[\"output_bias_mean\"],\n",
    "        output_bias_stddev=hyperparams.model[\"output_bias_stddev\"],\n",
    "        hidden_dim=hyperparams.model[\"hidden_dim\"],\n",
    "        num_outputs=1,\n",
    "    ),\n",
    "    dataset=kaggle_housing_dataset,\n",
    "    # loss=RMSLELoss,\n",
    "    loss=RMSELoss,\n",
    "    opt=torch.optim.SGD,\n",
    "    hyperparameters=hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralph/.venvs/d2dl/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model_trainer = provider(trainer.Hyperparameters(\n",
    "    opt=dict(\n",
    "        lr = 3e-3\n",
    "    ),\n",
    "    model=dict(\n",
    "        output_bias_mean = kaggle_housing_dataset.train.dataframe[\"SalePrice\"].mean(),\n",
    "        output_bias_stddev = kaggle_housing_dataset.train.dataframe[\"SalePrice\"].std(),\n",
    "        hidden_dim = 300\n",
    "    ),\n",
    "    general=dict(\n",
    "        num_epochs = 200,\n",
    "        batch_size = 64\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(13.3269, grad_fn=<MeanBackward0>) tensor(12.0617) tensor(1.3059, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.3189, grad_fn=<MeanBackward0>) tensor(11.9479) tensor(1.4339, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.3151, grad_fn=<MeanBackward0>) tensor(12.0542) tensor(1.3133, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.3084, grad_fn=<MeanBackward0>) tensor(11.9056) tensor(1.4626, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.3026, grad_fn=<MeanBackward0>) tensor(12.0108) tensor(1.3536, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2989, grad_fn=<MeanBackward0>) tensor(12.0278) tensor(1.3238, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2927, grad_fn=<MeanBackward0>) tensor(12.0345) tensor(1.3371, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2854, grad_fn=<MeanBackward0>) tensor(12.0919) tensor(1.2554, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2769, grad_fn=<MeanBackward0>) tensor(11.9523) tensor(1.3724, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2737, grad_fn=<MeanBackward0>) tensor(11.9576) tensor(1.3703, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2712, grad_fn=<MeanBackward0>) tensor(12.0705) tensor(1.2619, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2599, grad_fn=<MeanBackward0>) tensor(12.0222) tensor(1.2760, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2575, grad_fn=<MeanBackward0>) tensor(12.0493) tensor(1.2867, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2485, grad_fn=<MeanBackward0>) tensor(11.9638) tensor(1.3466, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2450, grad_fn=<MeanBackward0>) tensor(11.9372) tensor(1.3641, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2374, grad_fn=<MeanBackward0>) tensor(11.9607) tensor(1.3295, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2336, grad_fn=<MeanBackward0>) tensor(11.9911) tensor(1.3149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2275, grad_fn=<MeanBackward0>) tensor(12.0093) tensor(1.2972, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2211, grad_fn=<MeanBackward0>) tensor(12.0101) tensor(1.2917, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2167, grad_fn=<MeanBackward0>) tensor(12.0889) tensor(1.2036, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2124, grad_fn=<MeanBackward0>) tensor(12.1210) tensor(1.1509, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.2047, grad_fn=<MeanBackward0>) tensor(12.0197) tensor(1.2406, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1987, grad_fn=<MeanBackward0>) tensor(12.0492) tensor(1.2155, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1933, grad_fn=<MeanBackward0>) tensor(11.9175) tensor(1.3330, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1874, grad_fn=<MeanBackward0>) tensor(12.0753) tensor(1.1991, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1842, grad_fn=<MeanBackward0>) tensor(12.0442) tensor(1.2013, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1750, grad_fn=<MeanBackward0>) tensor(11.9790) tensor(1.2497, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1709, grad_fn=<MeanBackward0>) tensor(12.0110) tensor(1.2210, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1643, grad_fn=<MeanBackward0>) tensor(11.9632) tensor(1.2446, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1570, grad_fn=<MeanBackward0>) tensor(12.0640) tensor(1.1589, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1521, grad_fn=<MeanBackward0>) tensor(12.0025) tensor(1.2253, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1481, grad_fn=<MeanBackward0>) tensor(12.1142) tensor(1.1052, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1437, grad_fn=<MeanBackward0>) tensor(11.9349) tensor(1.2677, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1372, grad_fn=<MeanBackward0>) tensor(12.0961) tensor(1.0924, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1260, grad_fn=<MeanBackward0>) tensor(11.9780) tensor(1.2317, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1242, grad_fn=<MeanBackward0>) tensor(12.0307) tensor(1.1400, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1186, grad_fn=<MeanBackward0>) tensor(11.9794) tensor(1.2075, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1127, grad_fn=<MeanBackward0>) tensor(12.0342) tensor(1.1497, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1021, grad_fn=<MeanBackward0>) tensor(11.9931) tensor(1.1911, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.1000, grad_fn=<MeanBackward0>) tensor(12.0086) tensor(1.1652, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0920, grad_fn=<MeanBackward0>) tensor(11.9882) tensor(1.1650, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0884, grad_fn=<MeanBackward0>) tensor(11.9745) tensor(1.1685, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0819, grad_fn=<MeanBackward0>) tensor(12.0263) tensor(1.1476, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0733, grad_fn=<MeanBackward0>) tensor(12.0089) tensor(1.1280, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0701, grad_fn=<MeanBackward0>) tensor(12.0157) tensor(1.1295, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0649, grad_fn=<MeanBackward0>) tensor(12.0754) tensor(1.0463, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0558, grad_fn=<MeanBackward0>) tensor(12.0483) tensor(1.1264, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0507, grad_fn=<MeanBackward0>) tensor(12.0597) tensor(1.0595, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0469, grad_fn=<MeanBackward0>) tensor(12.0254) tensor(1.0991, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0400, grad_fn=<MeanBackward0>) tensor(12.0145) tensor(1.0978, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0309, grad_fn=<MeanBackward0>) tensor(12.0263) tensor(1.0717, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0284, grad_fn=<MeanBackward0>) tensor(11.9986) tensor(1.0831, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0209, grad_fn=<MeanBackward0>) tensor(11.9324) tensor(1.1488, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0114, grad_fn=<MeanBackward0>) tensor(12.0805) tensor(1.0269, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0075, grad_fn=<MeanBackward0>) tensor(12.1575) tensor(0.9209, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(13.0031, grad_fn=<MeanBackward0>) tensor(12.0632) tensor(1.0161, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9962, grad_fn=<MeanBackward0>) tensor(12.0442) tensor(1.0044, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9934, grad_fn=<MeanBackward0>) tensor(12.0153) tensor(1.0583, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9852, grad_fn=<MeanBackward0>) tensor(12.0755) tensor(0.9914, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9757, grad_fn=<MeanBackward0>) tensor(12.0423) tensor(1.0325, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9755, grad_fn=<MeanBackward0>) tensor(12.0694) tensor(0.9828, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9653, grad_fn=<MeanBackward0>) tensor(12.0161) tensor(1.0578, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9596, grad_fn=<MeanBackward0>) tensor(12.0309) tensor(1.0070, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9467, grad_fn=<MeanBackward0>) tensor(11.9893) tensor(1.0141, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9480, grad_fn=<MeanBackward0>) tensor(12.0331) tensor(0.9999, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9369, grad_fn=<MeanBackward0>) tensor(11.9577) tensor(1.0461, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9349, grad_fn=<MeanBackward0>) tensor(12.0867) tensor(0.9329, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9258, grad_fn=<MeanBackward0>) tensor(11.9254) tensor(1.0590, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9188, grad_fn=<MeanBackward0>) tensor(11.9782) tensor(1.0325, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9150, grad_fn=<MeanBackward0>) tensor(11.9967) tensor(1.0051, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.9050, grad_fn=<MeanBackward0>) tensor(11.9421) tensor(1.0373, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8964, grad_fn=<MeanBackward0>) tensor(12.0230) tensor(0.9699, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8927, grad_fn=<MeanBackward0>) tensor(11.9761) tensor(0.9678, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8904, grad_fn=<MeanBackward0>) tensor(12.0317) tensor(0.9524, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8751, grad_fn=<MeanBackward0>) tensor(12.0102) tensor(0.9590, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8711, grad_fn=<MeanBackward0>) tensor(12.0694) tensor(0.8991, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8634, grad_fn=<MeanBackward0>) tensor(12.0685) tensor(0.9020, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8571, grad_fn=<MeanBackward0>) tensor(12.0440) tensor(0.9098, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8489, grad_fn=<MeanBackward0>) tensor(11.9608) tensor(0.9603, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8444, grad_fn=<MeanBackward0>) tensor(12.0152) tensor(0.8950, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8336, grad_fn=<MeanBackward0>) tensor(12.1237) tensor(0.8450, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8268, grad_fn=<MeanBackward0>) tensor(11.9954) tensor(0.9329, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8237, grad_fn=<MeanBackward0>) tensor(11.9617) tensor(0.9364, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8161, grad_fn=<MeanBackward0>) tensor(12.0398) tensor(0.8552, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8132, grad_fn=<MeanBackward0>) tensor(12.0062) tensor(0.9049, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.8051, grad_fn=<MeanBackward0>) tensor(12.0339) tensor(0.8413, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7965, grad_fn=<MeanBackward0>) tensor(11.9767) tensor(0.8906, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7868, grad_fn=<MeanBackward0>) tensor(11.9928) tensor(0.8931, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7774, grad_fn=<MeanBackward0>) tensor(12.0511) tensor(0.8736, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7688, grad_fn=<MeanBackward0>) tensor(12.0184) tensor(0.8931, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7592, grad_fn=<MeanBackward0>) tensor(11.9916) tensor(0.8785, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7562, grad_fn=<MeanBackward0>) tensor(12.0781) tensor(0.7606, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7507, grad_fn=<MeanBackward0>) tensor(12.0470) tensor(0.7884, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7380, grad_fn=<MeanBackward0>) tensor(11.9496) tensor(0.8973, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7295, grad_fn=<MeanBackward0>) tensor(11.9527) tensor(0.8623, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7243, grad_fn=<MeanBackward0>) tensor(11.9235) tensor(0.8669, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7127, grad_fn=<MeanBackward0>) tensor(11.9757) tensor(0.8054, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.7030, grad_fn=<MeanBackward0>) tensor(11.9674) tensor(0.8182, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6993, grad_fn=<MeanBackward0>) tensor(12.0484) tensor(0.7645, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6904, grad_fn=<MeanBackward0>) tensor(11.9915) tensor(0.8256, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6805, grad_fn=<MeanBackward0>) tensor(11.9383) tensor(0.8365, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6679, grad_fn=<MeanBackward0>) tensor(12.1049) tensor(0.7027, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6634, grad_fn=<MeanBackward0>) tensor(11.9450) tensor(0.7951, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6560, grad_fn=<MeanBackward0>) tensor(11.9598) tensor(0.8130, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6466, grad_fn=<MeanBackward0>) tensor(11.9560) tensor(0.7861, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6345, grad_fn=<MeanBackward0>) tensor(11.9284) tensor(0.7989, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6291, grad_fn=<MeanBackward0>) tensor(12.0584) tensor(0.6916, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6261, grad_fn=<MeanBackward0>) tensor(12.0911) tensor(0.6583, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6112, grad_fn=<MeanBackward0>) tensor(12.0693) tensor(0.6913, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.6002, grad_fn=<MeanBackward0>) tensor(11.9917) tensor(0.7066, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5953, grad_fn=<MeanBackward0>) tensor(11.9784) tensor(0.7410, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5857, grad_fn=<MeanBackward0>) tensor(12.0005) tensor(0.6697, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5693, grad_fn=<MeanBackward0>) tensor(11.9876) tensor(0.6939, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5680, grad_fn=<MeanBackward0>) tensor(11.9873) tensor(0.6647, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5616, grad_fn=<MeanBackward0>) tensor(12.0022) tensor(0.6573, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5414, grad_fn=<MeanBackward0>) tensor(12.0975) tensor(0.5857, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5385, grad_fn=<MeanBackward0>) tensor(11.9983) tensor(0.6570, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5233, grad_fn=<MeanBackward0>) tensor(11.8886) tensor(0.7466, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5148, grad_fn=<MeanBackward0>) tensor(12.0334) tensor(0.6161, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.5076, grad_fn=<MeanBackward0>) tensor(12.0238) tensor(0.6131, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4984, grad_fn=<MeanBackward0>) tensor(12.0526) tensor(0.6356, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4845, grad_fn=<MeanBackward0>) tensor(12.0213) tensor(0.5905, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4763, grad_fn=<MeanBackward0>) tensor(12.0401) tensor(0.5867, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4527, grad_fn=<MeanBackward0>) tensor(11.9375) tensor(0.6250, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4571, grad_fn=<MeanBackward0>) tensor(12.0372) tensor(0.5986, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4476, grad_fn=<MeanBackward0>) tensor(12.0932) tensor(0.5520, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4363, grad_fn=<MeanBackward0>) tensor(12.0561) tensor(0.5411, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4245, grad_fn=<MeanBackward0>) tensor(12.0088) tensor(0.5534, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4138, grad_fn=<MeanBackward0>) tensor(12.0095) tensor(0.5889, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.4048, grad_fn=<MeanBackward0>) tensor(12.0542) tensor(0.4593, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3859, grad_fn=<MeanBackward0>) tensor(11.9701) tensor(0.5512, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3814, grad_fn=<MeanBackward0>) tensor(12.0603) tensor(0.4710, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3722, grad_fn=<MeanBackward0>) tensor(11.9832) tensor(0.5887, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3596, grad_fn=<MeanBackward0>) tensor(12.0461) tensor(0.4755, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3546, grad_fn=<MeanBackward0>) tensor(12.0815) tensor(0.5244, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3439, grad_fn=<MeanBackward0>) tensor(11.9894) tensor(0.5197, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3288, grad_fn=<MeanBackward0>) tensor(11.9171) tensor(0.5737, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3184, grad_fn=<MeanBackward0>) tensor(12.0562) tensor(0.5200, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.3029, grad_fn=<MeanBackward0>) tensor(11.9752) tensor(0.5190, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2941, grad_fn=<MeanBackward0>) tensor(12.0656) tensor(0.4272, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2871, grad_fn=<MeanBackward0>) tensor(11.9938) tensor(0.4599, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2870, grad_fn=<MeanBackward0>) tensor(12.0664) tensor(0.4596, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2735, grad_fn=<MeanBackward0>) tensor(11.9849) tensor(0.3963, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2583, grad_fn=<MeanBackward0>) tensor(12.0182) tensor(0.4239, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2461, grad_fn=<MeanBackward0>) tensor(12.0384) tensor(0.4735, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2322, grad_fn=<MeanBackward0>) tensor(12.0616) tensor(0.4541, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2078, grad_fn=<MeanBackward0>) tensor(12.0088) tensor(0.3468, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2258, grad_fn=<MeanBackward0>) tensor(12.0802) tensor(0.3272, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.2157, grad_fn=<MeanBackward0>) tensor(11.9614) tensor(0.4333, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1834, grad_fn=<MeanBackward0>) tensor(12.0126) tensor(0.4021, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1965, grad_fn=<MeanBackward0>) tensor(11.9914) tensor(0.3630, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1826, grad_fn=<MeanBackward0>) tensor(12.0723) tensor(0.3766, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1672, grad_fn=<MeanBackward0>) tensor(12.0054) tensor(0.3640, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1629, grad_fn=<MeanBackward0>) tensor(12.0440) tensor(0.3527, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1566, grad_fn=<MeanBackward0>) tensor(12.0270) tensor(0.4020, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1270, grad_fn=<MeanBackward0>) tensor(11.9814) tensor(0.3704, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1313, grad_fn=<MeanBackward0>) tensor(11.9459) tensor(0.4193, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1285, grad_fn=<MeanBackward0>) tensor(11.9863) tensor(0.3837, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1217, grad_fn=<MeanBackward0>) tensor(12.0122) tensor(0.3744, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0983, grad_fn=<MeanBackward0>) tensor(12.0295) tensor(0.4161, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1076, grad_fn=<MeanBackward0>) tensor(12.0348) tensor(0.3588, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1035, grad_fn=<MeanBackward0>) tensor(11.9733) tensor(0.3562, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0862, grad_fn=<MeanBackward0>) tensor(11.9805) tensor(0.3831, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1023, grad_fn=<MeanBackward0>) tensor(12.0150) tensor(0.3836, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0887, grad_fn=<MeanBackward0>) tensor(12.0437) tensor(0.3026, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0857, grad_fn=<MeanBackward0>) tensor(12.0295) tensor(0.3853, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0862, grad_fn=<MeanBackward0>) tensor(12.1258) tensor(0.3441, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0716, grad_fn=<MeanBackward0>) tensor(12.0684) tensor(0.3711, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0698, grad_fn=<MeanBackward0>) tensor(12.0024) tensor(0.3609, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0709, grad_fn=<MeanBackward0>) tensor(12.0015) tensor(0.3089, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0736, grad_fn=<MeanBackward0>) tensor(12.0138) tensor(0.2704, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0558, grad_fn=<MeanBackward0>) tensor(11.9861) tensor(0.3130, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0709, grad_fn=<MeanBackward0>) tensor(12.0430) tensor(0.3534, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0564, grad_fn=<MeanBackward0>) tensor(12.0621) tensor(0.2723, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0448, grad_fn=<MeanBackward0>) tensor(12.0254) tensor(0.3649, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0620, grad_fn=<MeanBackward0>) tensor(12.0671) tensor(0.3281, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0482, grad_fn=<MeanBackward0>) tensor(12.0037) tensor(0.3580, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0363, grad_fn=<MeanBackward0>) tensor(11.9809) tensor(0.3243, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0564, grad_fn=<MeanBackward0>) tensor(12.0528) tensor(0.3561, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0311, grad_fn=<MeanBackward0>) tensor(12.0132) tensor(0.2849, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0343, grad_fn=<MeanBackward0>) tensor(12.0044) tensor(0.3301, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0443, grad_fn=<MeanBackward0>) tensor(12.0958) tensor(0.3263, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0384, grad_fn=<MeanBackward0>) tensor(12.0413) tensor(0.3110, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0191, grad_fn=<MeanBackward0>) tensor(11.9354) tensor(0.3219, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0330, grad_fn=<MeanBackward0>) tensor(12.0351) tensor(0.3346, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0204, grad_fn=<MeanBackward0>) tensor(11.9422) tensor(0.2878, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0078, grad_fn=<MeanBackward0>) tensor(11.9709) tensor(0.3684, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0076, grad_fn=<MeanBackward0>) tensor(11.9938) tensor(0.3873, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0029, grad_fn=<MeanBackward0>) tensor(12.0260) tensor(0.2678, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0030, grad_fn=<MeanBackward0>) tensor(11.9876) tensor(0.3459, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0120, grad_fn=<MeanBackward0>) tensor(12.0153) tensor(0.3564, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9920, grad_fn=<MeanBackward0>) tensor(11.9913) tensor(0.2964, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0124, grad_fn=<MeanBackward0>) tensor(11.9993) tensor(0.2634, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9899, grad_fn=<MeanBackward0>) tensor(11.9954) tensor(0.3219, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9844, grad_fn=<MeanBackward0>) tensor(11.9407) tensor(0.3340, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9852, grad_fn=<MeanBackward0>) tensor(11.9771) tensor(0.2724, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9975, grad_fn=<MeanBackward0>) tensor(12.0114) tensor(0.2976, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9879, grad_fn=<MeanBackward0>) tensor(12.0032) tensor(0.2744, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0068, grad_fn=<MeanBackward0>) tensor(12.0485) tensor(0.3652, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0085, grad_fn=<MeanBackward0>) tensor(12.0024) tensor(0.2986, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9995, grad_fn=<MeanBackward0>) tensor(12.0104) tensor(0.2610, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9721, grad_fn=<MeanBackward0>) tensor(11.9644) tensor(0.2630, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9724, grad_fn=<MeanBackward0>) tensor(12.0319) tensor(0.2641, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9957, grad_fn=<MeanBackward0>) tensor(11.9955) tensor(0.2946, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0196, grad_fn=<MeanBackward0>) tensor(12.0582) tensor(0.2612, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0072, grad_fn=<MeanBackward0>) tensor(11.9866) tensor(0.2980, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0229, grad_fn=<MeanBackward0>) tensor(12.0908) tensor(0.2854, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9939, grad_fn=<MeanBackward0>) tensor(12.0099) tensor(0.2264, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0058, grad_fn=<MeanBackward0>) tensor(11.9775) tensor(0.3290, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0010, grad_fn=<MeanBackward0>) tensor(12.0525) tensor(0.2736, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9778, grad_fn=<MeanBackward0>) tensor(11.9721) tensor(0.2675, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9980, grad_fn=<MeanBackward0>) tensor(12.0380) tensor(0.2714, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9886, grad_fn=<MeanBackward0>) tensor(12.0101) tensor(0.2654, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9995, grad_fn=<MeanBackward0>) tensor(12.0530) tensor(0.2346, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0049, grad_fn=<MeanBackward0>) tensor(12.0400) tensor(0.2869, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9936, grad_fn=<MeanBackward0>) tensor(11.9523) tensor(0.2648, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9819, grad_fn=<MeanBackward0>) tensor(12.0157) tensor(0.2724, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9767, grad_fn=<MeanBackward0>) tensor(11.9749) tensor(0.2957, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9829, grad_fn=<MeanBackward0>) tensor(11.9736) tensor(0.2755, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0022, grad_fn=<MeanBackward0>) tensor(12.0929) tensor(0.3074, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9922, grad_fn=<MeanBackward0>) tensor(12.0001) tensor(0.2199, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9997, grad_fn=<MeanBackward0>) tensor(12.0471) tensor(0.3027, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9824, grad_fn=<MeanBackward0>) tensor(12.0222) tensor(0.2058, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9981, grad_fn=<MeanBackward0>) tensor(12.0498) tensor(0.2801, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0032, grad_fn=<MeanBackward0>) tensor(12.0253) tensor(0.2390, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0136, grad_fn=<MeanBackward0>) tensor(11.9845) tensor(0.2372, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9878, grad_fn=<MeanBackward0>) tensor(11.9828) tensor(0.2162, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0240, grad_fn=<MeanBackward0>) tensor(12.0862) tensor(0.2312, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0058, grad_fn=<MeanBackward0>) tensor(12.0420) tensor(0.2770, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0019, grad_fn=<MeanBackward0>) tensor(12.0519) tensor(0.2177, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0471, grad_fn=<MeanBackward0>) tensor(12.0713) tensor(0.2145, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0252, grad_fn=<MeanBackward0>) tensor(12.0557) tensor(0.3074, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9874, grad_fn=<MeanBackward0>) tensor(12.0000) tensor(0.2417, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0123, grad_fn=<MeanBackward0>) tensor(12.0337) tensor(0.2696, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9514, grad_fn=<MeanBackward0>) tensor(11.9050) tensor(0.1800, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9461, grad_fn=<MeanBackward0>) tensor(11.9094) tensor(0.2285, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9956, grad_fn=<MeanBackward0>) tensor(12.0022) tensor(0.2726, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9630, grad_fn=<MeanBackward0>) tensor(12.0120) tensor(0.2898, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0386, grad_fn=<MeanBackward0>) tensor(12.1162) tensor(0.2989, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0114, grad_fn=<MeanBackward0>) tensor(12.0155) tensor(0.2650, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9893, grad_fn=<MeanBackward0>) tensor(12.0473) tensor(0.2861, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0080, grad_fn=<MeanBackward0>) tensor(12.0370) tensor(0.2605, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0173, grad_fn=<MeanBackward0>) tensor(12.0928) tensor(0.2412, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0060, grad_fn=<MeanBackward0>) tensor(12.0032) tensor(0.1908, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0157, grad_fn=<MeanBackward0>) tensor(11.9930) tensor(0.2639, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9641, grad_fn=<MeanBackward0>) tensor(11.9818) tensor(0.2552, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0042, grad_fn=<MeanBackward0>) tensor(12.0749) tensor(0.2338, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0043, grad_fn=<MeanBackward0>) tensor(12.0191) tensor(0.2255, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0108, grad_fn=<MeanBackward0>) tensor(11.9971) tensor(0.2158, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0191, grad_fn=<MeanBackward0>) tensor(12.1125) tensor(0.2757, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0073, grad_fn=<MeanBackward0>) tensor(12.0492) tensor(0.1858, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0224, grad_fn=<MeanBackward0>) tensor(12.0168) tensor(0.2149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0208, grad_fn=<MeanBackward0>) tensor(12.0838) tensor(0.2606, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9808, grad_fn=<MeanBackward0>) tensor(11.9670) tensor(0.2145, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0257, grad_fn=<MeanBackward0>) tensor(12.0609) tensor(0.2214, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0107, grad_fn=<MeanBackward0>) tensor(11.9865) tensor(0.2459, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0121, grad_fn=<MeanBackward0>) tensor(12.0263) tensor(0.2687, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0540, grad_fn=<MeanBackward0>) tensor(12.0862) tensor(0.2283, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9566, grad_fn=<MeanBackward0>) tensor(11.9195) tensor(0.2699, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0124, grad_fn=<MeanBackward0>) tensor(12.0483) tensor(0.1855, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9718, grad_fn=<MeanBackward0>) tensor(11.9698) tensor(0.2375, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0107, grad_fn=<MeanBackward0>) tensor(12.0414) tensor(0.1982, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0049, grad_fn=<MeanBackward0>) tensor(12.0145) tensor(0.2089, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9981, grad_fn=<MeanBackward0>) tensor(11.9761) tensor(0.2405, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0174, grad_fn=<MeanBackward0>) tensor(12.0474) tensor(0.2214, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9775, grad_fn=<MeanBackward0>) tensor(12.0171) tensor(0.2084, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0414, grad_fn=<MeanBackward0>) tensor(12.0613) tensor(0.2397, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0065, grad_fn=<MeanBackward0>) tensor(12.0963) tensor(0.2651, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0384, grad_fn=<MeanBackward0>) tensor(12.0288) tensor(0.2354, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9803, grad_fn=<MeanBackward0>) tensor(11.9948) tensor(0.2112, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0383, grad_fn=<MeanBackward0>) tensor(12.0787) tensor(0.2293, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0363, grad_fn=<MeanBackward0>) tensor(12.1056) tensor(0.1636, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0285, grad_fn=<MeanBackward0>) tensor(12.0066) tensor(0.2093, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0205, grad_fn=<MeanBackward0>) tensor(12.0645) tensor(0.3269, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9907, grad_fn=<MeanBackward0>) tensor(11.9765) tensor(0.1821, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0268, grad_fn=<MeanBackward0>) tensor(12.0893) tensor(0.2037, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0356, grad_fn=<MeanBackward0>) tensor(12.0467) tensor(0.1592, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0158, grad_fn=<MeanBackward0>) tensor(12.0638) tensor(0.1943, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9941, grad_fn=<MeanBackward0>) tensor(11.9530) tensor(0.1645, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0398, grad_fn=<MeanBackward0>) tensor(12.0281) tensor(0.2476, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0334, grad_fn=<MeanBackward0>) tensor(12.0473) tensor(0.2486, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9810, grad_fn=<MeanBackward0>) tensor(11.9842) tensor(0.1693, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9950, grad_fn=<MeanBackward0>) tensor(12.0077) tensor(0.2196, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0248, grad_fn=<MeanBackward0>) tensor(12.0334) tensor(0.2487, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0016, grad_fn=<MeanBackward0>) tensor(11.9966) tensor(0.2032, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9382, grad_fn=<MeanBackward0>) tensor(11.9275) tensor(0.1688, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0218, grad_fn=<MeanBackward0>) tensor(12.0286) tensor(0.1810, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0157, grad_fn=<MeanBackward0>) tensor(12.0462) tensor(0.1821, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9847, grad_fn=<MeanBackward0>) tensor(12.0379) tensor(0.2616, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0782, grad_fn=<MeanBackward0>) tensor(12.0854) tensor(0.1681, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0177, grad_fn=<MeanBackward0>) tensor(12.0362) tensor(0.2820, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0177, grad_fn=<MeanBackward0>) tensor(12.0483) tensor(0.1717, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0278, grad_fn=<MeanBackward0>) tensor(12.0780) tensor(0.2147, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0730, grad_fn=<MeanBackward0>) tensor(12.1129) tensor(0.2114, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0426, grad_fn=<MeanBackward0>) tensor(12.0597) tensor(0.2055, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9886, grad_fn=<MeanBackward0>) tensor(11.9975) tensor(0.2447, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9552, grad_fn=<MeanBackward0>) tensor(11.9459) tensor(0.1810, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9964, grad_fn=<MeanBackward0>) tensor(12.0222) tensor(0.1606, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9977, grad_fn=<MeanBackward0>) tensor(12.0061) tensor(0.2517, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9732, grad_fn=<MeanBackward0>) tensor(12.0046) tensor(0.2101, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9945, grad_fn=<MeanBackward0>) tensor(11.9774) tensor(0.2050, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9265, grad_fn=<MeanBackward0>) tensor(11.9244) tensor(0.1935, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0412, grad_fn=<MeanBackward0>) tensor(12.1024) tensor(0.2442, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0214, grad_fn=<MeanBackward0>) tensor(12.0221) tensor(0.2108, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0663, grad_fn=<MeanBackward0>) tensor(12.0680) tensor(0.1364, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9952, grad_fn=<MeanBackward0>) tensor(11.9820) tensor(0.2266, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0146, grad_fn=<MeanBackward0>) tensor(12.0625) tensor(0.1650, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0064, grad_fn=<MeanBackward0>) tensor(12.0113) tensor(0.1738, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9847, grad_fn=<MeanBackward0>) tensor(11.9694) tensor(0.1627, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9837, grad_fn=<MeanBackward0>) tensor(12.0039) tensor(0.1763, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0828, grad_fn=<MeanBackward0>) tensor(12.0974) tensor(0.1711, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0260, grad_fn=<MeanBackward0>) tensor(12.0513) tensor(0.1744, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9775, grad_fn=<MeanBackward0>) tensor(11.9979) tensor(0.2115, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0122, grad_fn=<MeanBackward0>) tensor(12.0209) tensor(0.1654, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9519, grad_fn=<MeanBackward0>) tensor(11.9814) tensor(0.2025, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0529, grad_fn=<MeanBackward0>) tensor(12.0394) tensor(0.1400, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9980, grad_fn=<MeanBackward0>) tensor(12.0498) tensor(0.1791, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9491, grad_fn=<MeanBackward0>) tensor(11.9671) tensor(0.1779, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9615, grad_fn=<MeanBackward0>) tensor(11.9256) tensor(0.2070, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9860, grad_fn=<MeanBackward0>) tensor(12.0074) tensor(0.1473, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9885, grad_fn=<MeanBackward0>) tensor(12.0230) tensor(0.2024, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0243, grad_fn=<MeanBackward0>) tensor(12.0136) tensor(0.1880, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0056, grad_fn=<MeanBackward0>) tensor(12.0455) tensor(0.1709, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9957, grad_fn=<MeanBackward0>) tensor(11.9983) tensor(0.2342, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0331, grad_fn=<MeanBackward0>) tensor(12.0563) tensor(0.1395, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0362, grad_fn=<MeanBackward0>) tensor(12.0668) tensor(0.1695, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0174, grad_fn=<MeanBackward0>) tensor(11.9991) tensor(0.1485, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9796, grad_fn=<MeanBackward0>) tensor(11.9871) tensor(0.1819, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0163, grad_fn=<MeanBackward0>) tensor(12.0359) tensor(0.2056, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0693, grad_fn=<MeanBackward0>) tensor(12.0939) tensor(0.1604, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9956, grad_fn=<MeanBackward0>) tensor(12.0032) tensor(0.2002, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0008, grad_fn=<MeanBackward0>) tensor(12.0155) tensor(0.1919, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0083, grad_fn=<MeanBackward0>) tensor(12.0378) tensor(0.1605, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0069, grad_fn=<MeanBackward0>) tensor(11.9898) tensor(0.2097, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0406, grad_fn=<MeanBackward0>) tensor(12.0403) tensor(0.1939, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0124, grad_fn=<MeanBackward0>) tensor(12.0224) tensor(0.1735, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9482, grad_fn=<MeanBackward0>) tensor(11.9473) tensor(0.1171, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9946, grad_fn=<MeanBackward0>) tensor(11.9872) tensor(0.1424, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9495, grad_fn=<MeanBackward0>) tensor(11.9544) tensor(0.1788, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0195, grad_fn=<MeanBackward0>) tensor(12.0677) tensor(0.1739, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9875, grad_fn=<MeanBackward0>) tensor(12.0124) tensor(0.2183, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0905, grad_fn=<MeanBackward0>) tensor(12.1065) tensor(0.2041, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9301, grad_fn=<MeanBackward0>) tensor(11.9271) tensor(0.1862, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0332, grad_fn=<MeanBackward0>) tensor(12.0354) tensor(0.1417, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0302, grad_fn=<MeanBackward0>) tensor(12.0780) tensor(0.1657, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0754, grad_fn=<MeanBackward0>) tensor(12.1036) tensor(0.1637, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9872, grad_fn=<MeanBackward0>) tensor(12.0136) tensor(0.1992, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0329, grad_fn=<MeanBackward0>) tensor(11.9909) tensor(0.1947, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9515, grad_fn=<MeanBackward0>) tensor(11.9612) tensor(0.2261, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0065, grad_fn=<MeanBackward0>) tensor(12.0429) tensor(0.1324, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9786, grad_fn=<MeanBackward0>) tensor(11.9429) tensor(0.1787, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0448, grad_fn=<MeanBackward0>) tensor(12.0648) tensor(0.1360, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0010, grad_fn=<MeanBackward0>) tensor(12.0204) tensor(0.1797, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1020, grad_fn=<MeanBackward0>) tensor(12.1082) tensor(0.1343, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0348, grad_fn=<MeanBackward0>) tensor(12.0556) tensor(0.1582, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0463, grad_fn=<MeanBackward0>) tensor(12.0667) tensor(0.1488, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0080, grad_fn=<MeanBackward0>) tensor(12.0278) tensor(0.1342, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0622, grad_fn=<MeanBackward0>) tensor(12.0619) tensor(0.1913, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0327, grad_fn=<MeanBackward0>) tensor(12.0478) tensor(0.2023, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0171, grad_fn=<MeanBackward0>) tensor(12.0442) tensor(0.1344, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0214, grad_fn=<MeanBackward0>) tensor(12.0051) tensor(0.1441, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0185, grad_fn=<MeanBackward0>) tensor(12.0192) tensor(0.1472, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0752, grad_fn=<MeanBackward0>) tensor(12.0464) tensor(0.1766, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0326, grad_fn=<MeanBackward0>) tensor(12.0498) tensor(0.1501, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9736, grad_fn=<MeanBackward0>) tensor(11.9970) tensor(0.2153, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0003, grad_fn=<MeanBackward0>) tensor(11.9845) tensor(0.1670, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0416, grad_fn=<MeanBackward0>) tensor(12.0624) tensor(0.1862, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9584, grad_fn=<MeanBackward0>) tensor(11.9409) tensor(0.1979, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0541, grad_fn=<MeanBackward0>) tensor(12.0662) tensor(0.1726, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0693, grad_fn=<MeanBackward0>) tensor(12.0864) tensor(0.1385, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0126, grad_fn=<MeanBackward0>) tensor(12.0237) tensor(0.1517, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0115, grad_fn=<MeanBackward0>) tensor(11.9892) tensor(0.1921, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9868, grad_fn=<MeanBackward0>) tensor(11.9829) tensor(0.1777, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0461, grad_fn=<MeanBackward0>) tensor(12.0553) tensor(0.1646, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0534, grad_fn=<MeanBackward0>) tensor(12.0478) tensor(0.1798, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0212, grad_fn=<MeanBackward0>) tensor(12.0397) tensor(0.1862, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0240, grad_fn=<MeanBackward0>) tensor(12.0297) tensor(0.1428, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9880, grad_fn=<MeanBackward0>) tensor(11.9816) tensor(0.1739, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9806, grad_fn=<MeanBackward0>) tensor(12.0054) tensor(0.1286, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0338, grad_fn=<MeanBackward0>) tensor(12.0743) tensor(0.1867, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9689, grad_fn=<MeanBackward0>) tensor(11.9641) tensor(0.1363, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0606, grad_fn=<MeanBackward0>) tensor(12.1057) tensor(0.1719, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0755, grad_fn=<MeanBackward0>) tensor(12.0732) tensor(0.2090, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9772, grad_fn=<MeanBackward0>) tensor(11.9482) tensor(0.1962, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0593, grad_fn=<MeanBackward0>) tensor(12.0475) tensor(0.1620, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0482, grad_fn=<MeanBackward0>) tensor(12.0696) tensor(0.1581, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0069, grad_fn=<MeanBackward0>) tensor(11.9794) tensor(0.1642, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9766, grad_fn=<MeanBackward0>) tensor(12.0319) tensor(0.1427, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9959, grad_fn=<MeanBackward0>) tensor(11.9904) tensor(0.1570, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9784, grad_fn=<MeanBackward0>) tensor(11.9618) tensor(0.2174, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9765, grad_fn=<MeanBackward0>) tensor(11.9500) tensor(0.1627, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9866, grad_fn=<MeanBackward0>) tensor(11.9733) tensor(0.2131, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0258, grad_fn=<MeanBackward0>) tensor(12.0327) tensor(0.1305, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9760, grad_fn=<MeanBackward0>) tensor(12.0152) tensor(0.2101, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0199, grad_fn=<MeanBackward0>) tensor(12.0063) tensor(0.1584, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0112, grad_fn=<MeanBackward0>) tensor(11.9910) tensor(0.1753, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0799, grad_fn=<MeanBackward0>) tensor(12.1052) tensor(0.1222, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0281, grad_fn=<MeanBackward0>) tensor(12.0552) tensor(0.1326, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0326, grad_fn=<MeanBackward0>) tensor(12.0238) tensor(0.1531, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0061, grad_fn=<MeanBackward0>) tensor(12.0462) tensor(0.1988, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0267, grad_fn=<MeanBackward0>) tensor(12.0511) tensor(0.1716, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0328, grad_fn=<MeanBackward0>) tensor(12.0478) tensor(0.1591, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1194, grad_fn=<MeanBackward0>) tensor(12.1211) tensor(0.1620, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0603, grad_fn=<MeanBackward0>) tensor(12.0152) tensor(0.1869, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0115, grad_fn=<MeanBackward0>) tensor(12.0050) tensor(0.2119, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0869, grad_fn=<MeanBackward0>) tensor(12.0986) tensor(0.1597, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0018, grad_fn=<MeanBackward0>) tensor(11.9796) tensor(0.1527, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0318, grad_fn=<MeanBackward0>) tensor(12.0580) tensor(0.2197, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0099, grad_fn=<MeanBackward0>) tensor(12.0217) tensor(0.1664, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0651, grad_fn=<MeanBackward0>) tensor(12.0829) tensor(0.1602, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0272, grad_fn=<MeanBackward0>) tensor(12.0048) tensor(0.1522, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9909, grad_fn=<MeanBackward0>) tensor(11.9876) tensor(0.1965, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0221, grad_fn=<MeanBackward0>) tensor(12.0255) tensor(0.1428, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9904, grad_fn=<MeanBackward0>) tensor(11.9917) tensor(0.1811, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9728, grad_fn=<MeanBackward0>) tensor(11.9773) tensor(0.1978, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0140, grad_fn=<MeanBackward0>) tensor(12.0193) tensor(0.1883, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9969, grad_fn=<MeanBackward0>) tensor(11.9642) tensor(0.1605, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9880, grad_fn=<MeanBackward0>) tensor(12.0239) tensor(0.1360, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0423, grad_fn=<MeanBackward0>) tensor(12.0397) tensor(0.2024, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9901, grad_fn=<MeanBackward0>) tensor(12.0251) tensor(0.1311, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9843, grad_fn=<MeanBackward0>) tensor(11.9844) tensor(0.2020, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0668, grad_fn=<MeanBackward0>) tensor(12.0765) tensor(0.1168, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9321, grad_fn=<MeanBackward0>) tensor(11.9137) tensor(0.1721, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9898, grad_fn=<MeanBackward0>) tensor(12.0257) tensor(0.1474, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0454, grad_fn=<MeanBackward0>) tensor(12.0006) tensor(0.1507, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9194, grad_fn=<MeanBackward0>) tensor(11.9365) tensor(0.1296, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0448, grad_fn=<MeanBackward0>) tensor(12.0432) tensor(0.1265, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0150, grad_fn=<MeanBackward0>) tensor(12.0291) tensor(0.1429, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0012, grad_fn=<MeanBackward0>) tensor(12.0097) tensor(0.1555, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0589, grad_fn=<MeanBackward0>) tensor(12.0411) tensor(0.1301, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0890, grad_fn=<MeanBackward0>) tensor(12.1067) tensor(0.1611, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0298, grad_fn=<MeanBackward0>) tensor(12.0067) tensor(0.1628, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0780, grad_fn=<MeanBackward0>) tensor(12.0752) tensor(0.1159, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9280, grad_fn=<MeanBackward0>) tensor(11.9357) tensor(0.1344, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9523, grad_fn=<MeanBackward0>) tensor(12.0132) tensor(0.1842, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9909, grad_fn=<MeanBackward0>) tensor(12.0123) tensor(0.1628, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0309, grad_fn=<MeanBackward0>) tensor(12.0173) tensor(0.1701, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0094, grad_fn=<MeanBackward0>) tensor(12.0384) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0841, grad_fn=<MeanBackward0>) tensor(12.0704) tensor(0.1790, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0302, grad_fn=<MeanBackward0>) tensor(12.0226) tensor(0.1762, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0071, grad_fn=<MeanBackward0>) tensor(12.0210) tensor(0.1118, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0067, grad_fn=<MeanBackward0>) tensor(11.9926) tensor(0.1487, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9731, grad_fn=<MeanBackward0>) tensor(11.9445) tensor(0.1394, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0531, grad_fn=<MeanBackward0>) tensor(12.0742) tensor(0.1970, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9886, grad_fn=<MeanBackward0>) tensor(12.0011) tensor(0.1514, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0482, grad_fn=<MeanBackward0>) tensor(12.0398) tensor(0.1551, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9634, grad_fn=<MeanBackward0>) tensor(11.9747) tensor(0.1587, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0266, grad_fn=<MeanBackward0>) tensor(11.9880) tensor(0.1783, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0025, grad_fn=<MeanBackward0>) tensor(12.0123) tensor(0.1544, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0249, grad_fn=<MeanBackward0>) tensor(12.0494) tensor(0.1604, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9563, grad_fn=<MeanBackward0>) tensor(11.9480) tensor(0.1635, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9928, grad_fn=<MeanBackward0>) tensor(12.0362) tensor(0.1539, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0198, grad_fn=<MeanBackward0>) tensor(12.0003) tensor(0.1720, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1312, grad_fn=<MeanBackward0>) tensor(12.1540) tensor(0.1317, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0555, grad_fn=<MeanBackward0>) tensor(12.0779) tensor(0.2162, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0317, grad_fn=<MeanBackward0>) tensor(12.0601) tensor(0.1600, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0769, grad_fn=<MeanBackward0>) tensor(12.0424) tensor(0.1751, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9971, grad_fn=<MeanBackward0>) tensor(11.9452) tensor(0.2094, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9523, grad_fn=<MeanBackward0>) tensor(11.9758) tensor(0.1833, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1126, grad_fn=<MeanBackward0>) tensor(12.1519) tensor(0.1688, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9948, grad_fn=<MeanBackward0>) tensor(12.0116) tensor(0.1408, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9668, grad_fn=<MeanBackward0>) tensor(11.9307) tensor(0.2141, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1033, grad_fn=<MeanBackward0>) tensor(12.1063) tensor(0.1139, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0145, grad_fn=<MeanBackward0>) tensor(12.0208) tensor(0.1218, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0433, grad_fn=<MeanBackward0>) tensor(12.0871) tensor(0.2083, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9781, grad_fn=<MeanBackward0>) tensor(11.9742) tensor(0.1817, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9772, grad_fn=<MeanBackward0>) tensor(11.9894) tensor(0.1803, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0766, grad_fn=<MeanBackward0>) tensor(12.0766) tensor(0.1447, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0099, grad_fn=<MeanBackward0>) tensor(12.0160) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0338, grad_fn=<MeanBackward0>) tensor(12.0190) tensor(0.1904, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0318, grad_fn=<MeanBackward0>) tensor(12.0242) tensor(0.1195, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0934, grad_fn=<MeanBackward0>) tensor(12.0982) tensor(0.1067, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0703, grad_fn=<MeanBackward0>) tensor(12.0537) tensor(0.1416, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9879, grad_fn=<MeanBackward0>) tensor(11.9988) tensor(0.1309, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0151, grad_fn=<MeanBackward0>) tensor(12.0376) tensor(0.1644, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9909, grad_fn=<MeanBackward0>) tensor(11.9831) tensor(0.1915, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0222, grad_fn=<MeanBackward0>) tensor(12.0189) tensor(0.2031, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0232, grad_fn=<MeanBackward0>) tensor(12.0649) tensor(0.1537, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0129, grad_fn=<MeanBackward0>) tensor(12.0133) tensor(0.1686, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0188, grad_fn=<MeanBackward0>) tensor(11.9770) tensor(0.1895, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9627, grad_fn=<MeanBackward0>) tensor(11.9376) tensor(0.1374, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1208, grad_fn=<MeanBackward0>) tensor(12.1391) tensor(0.1524, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9889, grad_fn=<MeanBackward0>) tensor(12.0095) tensor(0.1753, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9521, grad_fn=<MeanBackward0>) tensor(11.9352) tensor(0.1575, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0150, grad_fn=<MeanBackward0>) tensor(12.0238) tensor(0.1081, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0110, grad_fn=<MeanBackward0>) tensor(12.0114) tensor(0.1596, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0928, grad_fn=<MeanBackward0>) tensor(12.1104) tensor(0.1115, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0128, grad_fn=<MeanBackward0>) tensor(12.0033) tensor(0.1465, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0028, grad_fn=<MeanBackward0>) tensor(12.0188) tensor(0.1430, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0092, grad_fn=<MeanBackward0>) tensor(12.0226) tensor(0.1831, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0061, grad_fn=<MeanBackward0>) tensor(12.0107) tensor(0.1862, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0348, grad_fn=<MeanBackward0>) tensor(12.0325) tensor(0.1830, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0033, grad_fn=<MeanBackward0>) tensor(12.0194) tensor(0.1302, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0983, grad_fn=<MeanBackward0>) tensor(12.0862) tensor(0.1502, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0546, grad_fn=<MeanBackward0>) tensor(12.0547) tensor(0.1231, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9867, grad_fn=<MeanBackward0>) tensor(11.9763) tensor(0.1191, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0729, grad_fn=<MeanBackward0>) tensor(12.0468) tensor(0.1758, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0461, grad_fn=<MeanBackward0>) tensor(12.0606) tensor(0.1403, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0169, grad_fn=<MeanBackward0>) tensor(12.0425) tensor(0.1815, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0624, grad_fn=<MeanBackward0>) tensor(12.0336) tensor(0.1058, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9549, grad_fn=<MeanBackward0>) tensor(11.9509) tensor(0.1596, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0013, grad_fn=<MeanBackward0>) tensor(12.0276) tensor(0.1456, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0246, grad_fn=<MeanBackward0>) tensor(12.0344) tensor(0.1162, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9705, grad_fn=<MeanBackward0>) tensor(11.9661) tensor(0.1394, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0346, grad_fn=<MeanBackward0>) tensor(12.0345) tensor(0.1467, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0551, grad_fn=<MeanBackward0>) tensor(12.0663) tensor(0.1148, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9982, grad_fn=<MeanBackward0>) tensor(12.0070) tensor(0.1418, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9865, grad_fn=<MeanBackward0>) tensor(12.0087) tensor(0.1630, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0229, grad_fn=<MeanBackward0>) tensor(11.9922) tensor(0.1463, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0307, grad_fn=<MeanBackward0>) tensor(12.0463) tensor(0.1512, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9962, grad_fn=<MeanBackward0>) tensor(12.0132) tensor(0.1635, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1558, grad_fn=<MeanBackward0>) tensor(12.1612) tensor(0.1699, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9167, grad_fn=<MeanBackward0>) tensor(11.8851) tensor(0.1694, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9536, grad_fn=<MeanBackward0>) tensor(11.9239) tensor(0.1923, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9114, grad_fn=<MeanBackward0>) tensor(11.9469) tensor(0.1233, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0680, grad_fn=<MeanBackward0>) tensor(12.0802) tensor(0.1296, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9986, grad_fn=<MeanBackward0>) tensor(12.0327) tensor(0.1267, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0471, grad_fn=<MeanBackward0>) tensor(12.0273) tensor(0.1234, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0514, grad_fn=<MeanBackward0>) tensor(12.0229) tensor(0.1467, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9500, grad_fn=<MeanBackward0>) tensor(11.9549) tensor(0.1320, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0035, grad_fn=<MeanBackward0>) tensor(12.0002) tensor(0.1552, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9794, grad_fn=<MeanBackward0>) tensor(11.9871) tensor(0.1093, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0125, grad_fn=<MeanBackward0>) tensor(12.0100) tensor(0.1907, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1366, grad_fn=<MeanBackward0>) tensor(12.1651) tensor(0.1816, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0368, grad_fn=<MeanBackward0>) tensor(12.0399) tensor(0.1517, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9424, grad_fn=<MeanBackward0>) tensor(11.9094) tensor(0.1737, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9768, grad_fn=<MeanBackward0>) tensor(11.9876) tensor(0.1203, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0236, grad_fn=<MeanBackward0>) tensor(12.0172) tensor(0.1638, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0566, grad_fn=<MeanBackward0>) tensor(12.0620) tensor(0.1515, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9314, grad_fn=<MeanBackward0>) tensor(11.9416) tensor(0.1980, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0352, grad_fn=<MeanBackward0>) tensor(12.0381) tensor(0.1723, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0664, grad_fn=<MeanBackward0>) tensor(12.0746) tensor(0.1557, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0816, grad_fn=<MeanBackward0>) tensor(12.0887) tensor(0.1512, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9722, grad_fn=<MeanBackward0>) tensor(11.9746) tensor(0.1277, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0263, grad_fn=<MeanBackward0>) tensor(12.0348) tensor(0.1862, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9633, grad_fn=<MeanBackward0>) tensor(11.9306) tensor(0.1558, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0247, grad_fn=<MeanBackward0>) tensor(12.0319) tensor(0.1274, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9979, grad_fn=<MeanBackward0>) tensor(12.0199) tensor(0.1262, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0414, grad_fn=<MeanBackward0>) tensor(12.0556) tensor(0.1774, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9498, grad_fn=<MeanBackward0>) tensor(11.9379) tensor(0.1532, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9948, grad_fn=<MeanBackward0>) tensor(12.0115) tensor(0.1260, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0742, grad_fn=<MeanBackward0>) tensor(12.0641) tensor(0.1066, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9911, grad_fn=<MeanBackward0>) tensor(11.9864) tensor(0.1319, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0054, grad_fn=<MeanBackward0>) tensor(12.0294) tensor(0.1485, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0551, grad_fn=<MeanBackward0>) tensor(12.0026) tensor(0.1859, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1056, grad_fn=<MeanBackward0>) tensor(12.1407) tensor(0.1364, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0220, grad_fn=<MeanBackward0>) tensor(12.0116) tensor(0.1362, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0681, grad_fn=<MeanBackward0>) tensor(12.0901) tensor(0.1456, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0008, grad_fn=<MeanBackward0>) tensor(11.9923) tensor(0.1464, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0148, grad_fn=<MeanBackward0>) tensor(12.0393) tensor(0.2158, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9560, grad_fn=<MeanBackward0>) tensor(11.9808) tensor(0.1243, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9190, grad_fn=<MeanBackward0>) tensor(11.8964) tensor(0.1928, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0923, grad_fn=<MeanBackward0>) tensor(12.0759) tensor(0.1820, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0474, grad_fn=<MeanBackward0>) tensor(12.0365) tensor(0.1179, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0344, grad_fn=<MeanBackward0>) tensor(12.0269) tensor(0.1497, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9578, grad_fn=<MeanBackward0>) tensor(11.9617) tensor(0.1589, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0337, grad_fn=<MeanBackward0>) tensor(12.0486) tensor(0.1208, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9199, grad_fn=<MeanBackward0>) tensor(11.9262) tensor(0.2027, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0396, grad_fn=<MeanBackward0>) tensor(12.0281) tensor(0.1233, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0102, grad_fn=<MeanBackward0>) tensor(12.0038) tensor(0.1815, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9488, grad_fn=<MeanBackward0>) tensor(11.9576) tensor(0.1332, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0451, grad_fn=<MeanBackward0>) tensor(12.0572) tensor(0.1240, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0777, grad_fn=<MeanBackward0>) tensor(12.0833) tensor(0.0913, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9862, grad_fn=<MeanBackward0>) tensor(12.0188) tensor(0.1442, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9914, grad_fn=<MeanBackward0>) tensor(12.0079) tensor(0.1989, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0434, grad_fn=<MeanBackward0>) tensor(12.0524) tensor(0.1275, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9927, grad_fn=<MeanBackward0>) tensor(11.9713) tensor(0.1107, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0309, grad_fn=<MeanBackward0>) tensor(12.0495) tensor(0.1221, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0679, grad_fn=<MeanBackward0>) tensor(12.0236) tensor(0.1139, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0363, grad_fn=<MeanBackward0>) tensor(12.0532) tensor(0.1408, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0289, grad_fn=<MeanBackward0>) tensor(12.0346) tensor(0.1518, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0126, grad_fn=<MeanBackward0>) tensor(12.0148) tensor(0.1853, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0376, grad_fn=<MeanBackward0>) tensor(12.0281) tensor(0.1362, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9281, grad_fn=<MeanBackward0>) tensor(11.9318) tensor(0.1096, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0234, grad_fn=<MeanBackward0>) tensor(11.9980) tensor(0.1236, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0785, grad_fn=<MeanBackward0>) tensor(12.0997) tensor(0.1724, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0858, grad_fn=<MeanBackward0>) tensor(12.1149) tensor(0.1157, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1156, grad_fn=<MeanBackward0>) tensor(12.1242) tensor(0.1201, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9394, grad_fn=<MeanBackward0>) tensor(11.8880) tensor(0.1399, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0516, grad_fn=<MeanBackward0>) tensor(12.0298) tensor(0.1147, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0361, grad_fn=<MeanBackward0>) tensor(12.0514) tensor(0.1506, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0358, grad_fn=<MeanBackward0>) tensor(12.0611) tensor(0.1490, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0093, grad_fn=<MeanBackward0>) tensor(12.0176) tensor(0.1443, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0611, grad_fn=<MeanBackward0>) tensor(12.0370) tensor(0.1804, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0375, grad_fn=<MeanBackward0>) tensor(12.0650) tensor(0.1414, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9387, grad_fn=<MeanBackward0>) tensor(11.9839) tensor(0.1616, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0227, grad_fn=<MeanBackward0>) tensor(12.0503) tensor(0.1699, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0330, grad_fn=<MeanBackward0>) tensor(12.0299) tensor(0.1175, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0701, grad_fn=<MeanBackward0>) tensor(12.0662) tensor(0.1838, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0400, grad_fn=<MeanBackward0>) tensor(12.0333) tensor(0.1271, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9989, grad_fn=<MeanBackward0>) tensor(11.9760) tensor(0.1664, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0834, grad_fn=<MeanBackward0>) tensor(12.0628) tensor(0.1633, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.8923, grad_fn=<MeanBackward0>) tensor(11.9123) tensor(0.1772, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0309, grad_fn=<MeanBackward0>) tensor(12.0687) tensor(0.2155, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0558, grad_fn=<MeanBackward0>) tensor(12.0447) tensor(0.1360, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9676, grad_fn=<MeanBackward0>) tensor(11.9471) tensor(0.1156, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0533, grad_fn=<MeanBackward0>) tensor(12.0599) tensor(0.1128, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0287, grad_fn=<MeanBackward0>) tensor(12.0493) tensor(0.1505, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0082, grad_fn=<MeanBackward0>) tensor(11.9876) tensor(0.1729, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9752, grad_fn=<MeanBackward0>) tensor(11.9993) tensor(0.1389, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0769, grad_fn=<MeanBackward0>) tensor(12.0768) tensor(0.1568, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0575, grad_fn=<MeanBackward0>) tensor(12.0594) tensor(0.1465, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9206, grad_fn=<MeanBackward0>) tensor(11.9164) tensor(0.1628, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0705, grad_fn=<MeanBackward0>) tensor(12.1038) tensor(0.1959, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9441, grad_fn=<MeanBackward0>) tensor(11.9457) tensor(0.1108, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9995, grad_fn=<MeanBackward0>) tensor(11.9971) tensor(0.1636, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0265, grad_fn=<MeanBackward0>) tensor(12.0451) tensor(0.0955, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0711, grad_fn=<MeanBackward0>) tensor(12.0412) tensor(0.1760, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9734, grad_fn=<MeanBackward0>) tensor(11.9816) tensor(0.1427, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9908, grad_fn=<MeanBackward0>) tensor(11.9658) tensor(0.1668, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0564, grad_fn=<MeanBackward0>) tensor(12.0659) tensor(0.1556, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0303, grad_fn=<MeanBackward0>) tensor(12.0304) tensor(0.1238, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9647, grad_fn=<MeanBackward0>) tensor(11.9688) tensor(0.1195, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9790, grad_fn=<MeanBackward0>) tensor(12.0080) tensor(0.1536, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1028, grad_fn=<MeanBackward0>) tensor(12.1019) tensor(0.1652, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9933, grad_fn=<MeanBackward0>) tensor(11.9818) tensor(0.1325, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9968, grad_fn=<MeanBackward0>) tensor(12.0016) tensor(0.1180, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0578, grad_fn=<MeanBackward0>) tensor(12.0602) tensor(0.1323, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0869, grad_fn=<MeanBackward0>) tensor(12.0832) tensor(0.1608, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0239, grad_fn=<MeanBackward0>) tensor(12.0265) tensor(0.1450, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0795, grad_fn=<MeanBackward0>) tensor(12.0719) tensor(0.1467, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9561, grad_fn=<MeanBackward0>) tensor(11.9531) tensor(0.1365, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0248, grad_fn=<MeanBackward0>) tensor(11.9977) tensor(0.1276, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0195, grad_fn=<MeanBackward0>) tensor(12.0390) tensor(0.1637, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9884, grad_fn=<MeanBackward0>) tensor(12.0089) tensor(0.1789, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0452, grad_fn=<MeanBackward0>) tensor(12.0248) tensor(0.1245, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9834, grad_fn=<MeanBackward0>) tensor(11.9690) tensor(0.1745, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0144, grad_fn=<MeanBackward0>) tensor(12.0224) tensor(0.2067, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9973, grad_fn=<MeanBackward0>) tensor(11.9897) tensor(0.1825, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9930, grad_fn=<MeanBackward0>) tensor(11.9890) tensor(0.1355, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0716, grad_fn=<MeanBackward0>) tensor(12.0771) tensor(0.1735, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9777, grad_fn=<MeanBackward0>) tensor(11.9784) tensor(0.1218, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9596, grad_fn=<MeanBackward0>) tensor(11.9453) tensor(0.1290, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0790, grad_fn=<MeanBackward0>) tensor(12.1155) tensor(0.1553, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9135, grad_fn=<MeanBackward0>) tensor(11.9232) tensor(0.1409, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0656, grad_fn=<MeanBackward0>) tensor(12.0976) tensor(0.1149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0310, grad_fn=<MeanBackward0>) tensor(12.0068) tensor(0.2081, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0108, grad_fn=<MeanBackward0>) tensor(11.9992) tensor(0.1213, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9334, grad_fn=<MeanBackward0>) tensor(11.9145) tensor(0.1090, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0130, grad_fn=<MeanBackward0>) tensor(12.0326) tensor(0.1319, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0584, grad_fn=<MeanBackward0>) tensor(12.0540) tensor(0.1508, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9470, grad_fn=<MeanBackward0>) tensor(11.9568) tensor(0.1309, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0305, grad_fn=<MeanBackward0>) tensor(12.0215) tensor(0.1754, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0075, grad_fn=<MeanBackward0>) tensor(12.0193) tensor(0.1003, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9793, grad_fn=<MeanBackward0>) tensor(11.9825) tensor(0.1409, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0083, grad_fn=<MeanBackward0>) tensor(12.0110) tensor(0.1221, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0041, grad_fn=<MeanBackward0>) tensor(12.0123) tensor(0.1077, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9895, grad_fn=<MeanBackward0>) tensor(12.0093) tensor(0.2248, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0379, grad_fn=<MeanBackward0>) tensor(12.0166) tensor(0.1398, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9987, grad_fn=<MeanBackward0>) tensor(12.0094) tensor(0.1207, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9951, grad_fn=<MeanBackward0>) tensor(11.9659) tensor(0.1521, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9034, grad_fn=<MeanBackward0>) tensor(11.8965) tensor(0.1423, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9883, grad_fn=<MeanBackward0>) tensor(12.0130) tensor(0.1640, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9789, grad_fn=<MeanBackward0>) tensor(11.9890) tensor(0.1145, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0114, grad_fn=<MeanBackward0>) tensor(12.0186) tensor(0.1120, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0633, grad_fn=<MeanBackward0>) tensor(12.0558) tensor(0.1076, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0642, grad_fn=<MeanBackward0>) tensor(12.0630) tensor(0.1561, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9836, grad_fn=<MeanBackward0>) tensor(11.9721) tensor(0.1006, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9421, grad_fn=<MeanBackward0>) tensor(11.9102) tensor(0.2173, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0081, grad_fn=<MeanBackward0>) tensor(11.9941) tensor(0.1137, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0574, grad_fn=<MeanBackward0>) tensor(12.0653) tensor(0.1630, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0615, grad_fn=<MeanBackward0>) tensor(12.0582) tensor(0.1554, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9688, grad_fn=<MeanBackward0>) tensor(11.9685) tensor(0.1376, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0343, grad_fn=<MeanBackward0>) tensor(12.0479) tensor(0.1521, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9762, grad_fn=<MeanBackward0>) tensor(11.9667) tensor(0.1364, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9538, grad_fn=<MeanBackward0>) tensor(12.0134) tensor(0.1753, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0870, grad_fn=<MeanBackward0>) tensor(12.0961) tensor(0.1124, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0672, grad_fn=<MeanBackward0>) tensor(12.0674) tensor(0.1383, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0183, grad_fn=<MeanBackward0>) tensor(12.0335) tensor(0.1150, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9720, grad_fn=<MeanBackward0>) tensor(11.9956) tensor(0.1737, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9409, grad_fn=<MeanBackward0>) tensor(11.9208) tensor(0.1269, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9841, grad_fn=<MeanBackward0>) tensor(11.9563) tensor(0.1392, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0203, grad_fn=<MeanBackward0>) tensor(12.0409) tensor(0.1369, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0588, grad_fn=<MeanBackward0>) tensor(12.0595) tensor(0.1527, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9369, grad_fn=<MeanBackward0>) tensor(11.9598) tensor(0.1669, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0898, grad_fn=<MeanBackward0>) tensor(12.1025) tensor(0.1736, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9913, grad_fn=<MeanBackward0>) tensor(11.9539) tensor(0.1589, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0214, grad_fn=<MeanBackward0>) tensor(12.0121) tensor(0.1741, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0785, grad_fn=<MeanBackward0>) tensor(12.0706) tensor(0.1461, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9458, grad_fn=<MeanBackward0>) tensor(11.9825) tensor(0.1387, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0203, grad_fn=<MeanBackward0>) tensor(12.0577) tensor(0.1738, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0800, grad_fn=<MeanBackward0>) tensor(12.0878) tensor(0.1237, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9791, grad_fn=<MeanBackward0>) tensor(11.9686) tensor(0.0966, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0284, grad_fn=<MeanBackward0>) tensor(12.0310) tensor(0.1388, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9999, grad_fn=<MeanBackward0>) tensor(12.0008) tensor(0.1299, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9557, grad_fn=<MeanBackward0>) tensor(11.9758) tensor(0.1148, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0424, grad_fn=<MeanBackward0>) tensor(12.0295) tensor(0.1055, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0203, grad_fn=<MeanBackward0>) tensor(12.0162) tensor(0.1306, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1100, grad_fn=<MeanBackward0>) tensor(12.1079) tensor(0.1015, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9960, grad_fn=<MeanBackward0>) tensor(11.9988) tensor(0.1458, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9639, grad_fn=<MeanBackward0>) tensor(11.9720) tensor(0.1119, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0672, grad_fn=<MeanBackward0>) tensor(12.0668) tensor(0.1279, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0735, grad_fn=<MeanBackward0>) tensor(12.0867) tensor(0.1627, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0400, grad_fn=<MeanBackward0>) tensor(12.0228) tensor(0.1168, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0018, grad_fn=<MeanBackward0>) tensor(11.9738) tensor(0.1587, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1345, grad_fn=<MeanBackward0>) tensor(12.1438) tensor(0.1252, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9765, grad_fn=<MeanBackward0>) tensor(11.9547) tensor(0.1208, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0449, grad_fn=<MeanBackward0>) tensor(12.0380) tensor(0.1261, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0168, grad_fn=<MeanBackward0>) tensor(12.0360) tensor(0.1039, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9818, grad_fn=<MeanBackward0>) tensor(11.9935) tensor(0.1945, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0613, grad_fn=<MeanBackward0>) tensor(12.0320) tensor(0.1612, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9864, grad_fn=<MeanBackward0>) tensor(12.0253) tensor(0.1348, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9974, grad_fn=<MeanBackward0>) tensor(11.9960) tensor(0.1586, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9805, grad_fn=<MeanBackward0>) tensor(11.9785) tensor(0.1691, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9708, grad_fn=<MeanBackward0>) tensor(11.9735) tensor(0.1734, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0360, grad_fn=<MeanBackward0>) tensor(12.0530) tensor(0.1124, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0287, grad_fn=<MeanBackward0>) tensor(12.0199) tensor(0.1289, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0820, grad_fn=<MeanBackward0>) tensor(12.0849) tensor(0.1330, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0799, grad_fn=<MeanBackward0>) tensor(12.0791) tensor(0.1144, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9837, grad_fn=<MeanBackward0>) tensor(11.9758) tensor(0.1197, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9486, grad_fn=<MeanBackward0>) tensor(11.9486) tensor(0.1442, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0798, grad_fn=<MeanBackward0>) tensor(12.0972) tensor(0.1734, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0810, grad_fn=<MeanBackward0>) tensor(12.0783) tensor(0.1686, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0346, grad_fn=<MeanBackward0>) tensor(12.0655) tensor(0.1404, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0179, grad_fn=<MeanBackward0>) tensor(12.0070) tensor(0.1128, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.8853, grad_fn=<MeanBackward0>) tensor(11.8828) tensor(0.1732, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9997, grad_fn=<MeanBackward0>) tensor(11.9770) tensor(0.1161, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0627, grad_fn=<MeanBackward0>) tensor(12.0473) tensor(0.1186, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0456, grad_fn=<MeanBackward0>) tensor(12.0265) tensor(0.1149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0724, grad_fn=<MeanBackward0>) tensor(12.0795) tensor(0.1648, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9788, grad_fn=<MeanBackward0>) tensor(11.9870) tensor(0.1860, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9970, grad_fn=<MeanBackward0>) tensor(12.0231) tensor(0.1405, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9810, grad_fn=<MeanBackward0>) tensor(12.0133) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0141, grad_fn=<MeanBackward0>) tensor(11.9927) tensor(0.1559, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0610, grad_fn=<MeanBackward0>) tensor(12.0578) tensor(0.1023, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0849, grad_fn=<MeanBackward0>) tensor(12.0933) tensor(0.1341, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0740, grad_fn=<MeanBackward0>) tensor(12.0723) tensor(0.1359, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0116, grad_fn=<MeanBackward0>) tensor(12.0645) tensor(0.1771, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0424, grad_fn=<MeanBackward0>) tensor(12.0532) tensor(0.1111, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0596, grad_fn=<MeanBackward0>) tensor(12.0474) tensor(0.1285, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0000, grad_fn=<MeanBackward0>) tensor(12.0007) tensor(0.1835, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0691, grad_fn=<MeanBackward0>) tensor(12.0782) tensor(0.1141, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0031, grad_fn=<MeanBackward0>) tensor(11.9713) tensor(0.1291, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9754, grad_fn=<MeanBackward0>) tensor(11.9990) tensor(0.1469, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9462, grad_fn=<MeanBackward0>) tensor(11.9330) tensor(0.1135, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9611, grad_fn=<MeanBackward0>) tensor(11.9553) tensor(0.1404, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9808, grad_fn=<MeanBackward0>) tensor(11.9775) tensor(0.1647, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9533, grad_fn=<MeanBackward0>) tensor(11.9700) tensor(0.1284, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0197, grad_fn=<MeanBackward0>) tensor(11.9944) tensor(0.1399, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0409, grad_fn=<MeanBackward0>) tensor(12.0439) tensor(0.1160, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9894, grad_fn=<MeanBackward0>) tensor(11.9863) tensor(0.1733, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9851, grad_fn=<MeanBackward0>) tensor(11.9784) tensor(0.1497, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9839, grad_fn=<MeanBackward0>) tensor(11.9702) tensor(0.1646, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0060, grad_fn=<MeanBackward0>) tensor(11.9971) tensor(0.1100, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9859, grad_fn=<MeanBackward0>) tensor(12.0017) tensor(0.1103, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9817, grad_fn=<MeanBackward0>) tensor(11.9914) tensor(0.1477, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9524, grad_fn=<MeanBackward0>) tensor(11.9857) tensor(0.1464, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0421, grad_fn=<MeanBackward0>) tensor(12.0559) tensor(0.1127, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0846, grad_fn=<MeanBackward0>) tensor(12.0998) tensor(0.1211, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0288, grad_fn=<MeanBackward0>) tensor(12.0286) tensor(0.1405, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0189, grad_fn=<MeanBackward0>) tensor(12.0068) tensor(0.1723, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0293, grad_fn=<MeanBackward0>) tensor(12.0352) tensor(0.1379, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9272, grad_fn=<MeanBackward0>) tensor(11.9353) tensor(0.1605, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0404, grad_fn=<MeanBackward0>) tensor(12.0351) tensor(0.1531, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9552, grad_fn=<MeanBackward0>) tensor(11.9497) tensor(0.1163, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0928, grad_fn=<MeanBackward0>) tensor(12.1113) tensor(0.1456, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9911, grad_fn=<MeanBackward0>) tensor(11.9818) tensor(0.1572, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9971, grad_fn=<MeanBackward0>) tensor(11.9817) tensor(0.2114, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0143, grad_fn=<MeanBackward0>) tensor(12.0275) tensor(0.1507, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1249, grad_fn=<MeanBackward0>) tensor(12.1046) tensor(0.1031, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9724, grad_fn=<MeanBackward0>) tensor(11.9691) tensor(0.1017, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9978, grad_fn=<MeanBackward0>) tensor(12.0059) tensor(0.1654, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0631, grad_fn=<MeanBackward0>) tensor(12.0796) tensor(0.1387, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9990, grad_fn=<MeanBackward0>) tensor(11.9973) tensor(0.1109, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9372, grad_fn=<MeanBackward0>) tensor(11.9464) tensor(0.1076, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0567, grad_fn=<MeanBackward0>) tensor(12.0350) tensor(0.1691, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9814, grad_fn=<MeanBackward0>) tensor(11.9821) tensor(0.1479, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9787, grad_fn=<MeanBackward0>) tensor(11.9768) tensor(0.0985, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9988, grad_fn=<MeanBackward0>) tensor(12.0410) tensor(0.1411, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0376, grad_fn=<MeanBackward0>) tensor(12.0475) tensor(0.1407, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0283, grad_fn=<MeanBackward0>) tensor(12.0210) tensor(0.1444, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0520, grad_fn=<MeanBackward0>) tensor(12.0293) tensor(0.1174, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0290, grad_fn=<MeanBackward0>) tensor(12.0556) tensor(0.1103, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0279, grad_fn=<MeanBackward0>) tensor(12.0254) tensor(0.1567, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0388, grad_fn=<MeanBackward0>) tensor(12.0535) tensor(0.1191, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0795, grad_fn=<MeanBackward0>) tensor(12.0915) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9456, grad_fn=<MeanBackward0>) tensor(11.9476) tensor(0.1661, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0220, grad_fn=<MeanBackward0>) tensor(12.0193) tensor(0.1376, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0112, grad_fn=<MeanBackward0>) tensor(12.0171) tensor(0.1312, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9820, grad_fn=<MeanBackward0>) tensor(11.9711) tensor(0.1540, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9858, grad_fn=<MeanBackward0>) tensor(12.0028) tensor(0.1537, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0005, grad_fn=<MeanBackward0>) tensor(11.9871) tensor(0.1127, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0415, grad_fn=<MeanBackward0>) tensor(12.0622) tensor(0.1279, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0096, grad_fn=<MeanBackward0>) tensor(11.9959) tensor(0.1671, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0673, grad_fn=<MeanBackward0>) tensor(12.0735) tensor(0.1406, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0334, grad_fn=<MeanBackward0>) tensor(12.0264) tensor(0.1610, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0615, grad_fn=<MeanBackward0>) tensor(12.0446) tensor(0.1304, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9514, grad_fn=<MeanBackward0>) tensor(11.9359) tensor(0.1423, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0507, grad_fn=<MeanBackward0>) tensor(12.0598) tensor(0.1057, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9490, grad_fn=<MeanBackward0>) tensor(11.9430) tensor(0.1613, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0571, grad_fn=<MeanBackward0>) tensor(12.0633) tensor(0.1200, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9982, grad_fn=<MeanBackward0>) tensor(12.0040) tensor(0.1585, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0523, grad_fn=<MeanBackward0>) tensor(12.0881) tensor(0.1460, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0412, grad_fn=<MeanBackward0>) tensor(12.0367) tensor(0.1089, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0116, grad_fn=<MeanBackward0>) tensor(12.0234) tensor(0.1251, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9765, grad_fn=<MeanBackward0>) tensor(11.9275) tensor(0.2243, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9357, grad_fn=<MeanBackward0>) tensor(11.9454) tensor(0.1260, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9977, grad_fn=<MeanBackward0>) tensor(11.9683) tensor(0.1462, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9949, grad_fn=<MeanBackward0>) tensor(11.9949) tensor(0.1231, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9867, grad_fn=<MeanBackward0>) tensor(11.9931) tensor(0.1600, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9366, grad_fn=<MeanBackward0>) tensor(11.9385) tensor(0.1719, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0557, grad_fn=<MeanBackward0>) tensor(12.0627) tensor(0.1078, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0999, grad_fn=<MeanBackward0>) tensor(12.0992) tensor(0.1070, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0644, grad_fn=<MeanBackward0>) tensor(12.0672) tensor(0.1256, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9981, grad_fn=<MeanBackward0>) tensor(12.0026) tensor(0.1249, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9903, grad_fn=<MeanBackward0>) tensor(12.0063) tensor(0.1397, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0288, grad_fn=<MeanBackward0>) tensor(12.0425) tensor(0.1120, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0329, grad_fn=<MeanBackward0>) tensor(12.0413) tensor(0.1191, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1073, grad_fn=<MeanBackward0>) tensor(12.0720) tensor(0.1803, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9679, grad_fn=<MeanBackward0>) tensor(11.9631) tensor(0.1339, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0162, grad_fn=<MeanBackward0>) tensor(12.0233) tensor(0.1265, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0080, grad_fn=<MeanBackward0>) tensor(11.9803) tensor(0.1659, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0041, grad_fn=<MeanBackward0>) tensor(12.0091) tensor(0.1066, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0042, grad_fn=<MeanBackward0>) tensor(12.0393) tensor(0.1610, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9911, grad_fn=<MeanBackward0>) tensor(11.9772) tensor(0.1246, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0232, grad_fn=<MeanBackward0>) tensor(12.0420) tensor(0.1600, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0717, grad_fn=<MeanBackward0>) tensor(12.0738) tensor(0.1351, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9992, grad_fn=<MeanBackward0>) tensor(12.0337) tensor(0.1197, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0227, grad_fn=<MeanBackward0>) tensor(11.9972) tensor(0.1677, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9186, grad_fn=<MeanBackward0>) tensor(11.9175) tensor(0.1120, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0898, grad_fn=<MeanBackward0>) tensor(12.1124) tensor(0.1213, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0410, grad_fn=<MeanBackward0>) tensor(12.0285) tensor(0.1326, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0999, grad_fn=<MeanBackward0>) tensor(12.0886) tensor(0.1665, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9397, grad_fn=<MeanBackward0>) tensor(11.9351) tensor(0.1305, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9457, grad_fn=<MeanBackward0>) tensor(11.9475) tensor(0.1168, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0417, grad_fn=<MeanBackward0>) tensor(12.0406) tensor(0.1229, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0416, grad_fn=<MeanBackward0>) tensor(12.0209) tensor(0.1332, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0061, grad_fn=<MeanBackward0>) tensor(12.0102) tensor(0.1100, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9883, grad_fn=<MeanBackward0>) tensor(11.9865) tensor(0.1128, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0374, grad_fn=<MeanBackward0>) tensor(12.0350) tensor(0.1247, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9355, grad_fn=<MeanBackward0>) tensor(11.9301) tensor(0.1510, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0604, grad_fn=<MeanBackward0>) tensor(12.0925) tensor(0.1673, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1265, grad_fn=<MeanBackward0>) tensor(12.1351) tensor(0.1406, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0051, grad_fn=<MeanBackward0>) tensor(12.0035) tensor(0.1231, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0135, grad_fn=<MeanBackward0>) tensor(12.0144) tensor(0.1163, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0628, grad_fn=<MeanBackward0>) tensor(12.0535) tensor(0.1659, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9453, grad_fn=<MeanBackward0>) tensor(11.9238) tensor(0.1364, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0125, grad_fn=<MeanBackward0>) tensor(12.0174) tensor(0.1113, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0473, grad_fn=<MeanBackward0>) tensor(12.0614) tensor(0.1707, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0381, grad_fn=<MeanBackward0>) tensor(12.0553) tensor(0.1663, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9863, grad_fn=<MeanBackward0>) tensor(11.9634) tensor(0.1499, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0880, grad_fn=<MeanBackward0>) tensor(12.0962) tensor(0.1840, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9949, grad_fn=<MeanBackward0>) tensor(11.9756) tensor(0.1237, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0477, grad_fn=<MeanBackward0>) tensor(12.0667) tensor(0.1647, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0753, grad_fn=<MeanBackward0>) tensor(12.0609) tensor(0.1168, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9728, grad_fn=<MeanBackward0>) tensor(11.9831) tensor(0.1298, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0368, grad_fn=<MeanBackward0>) tensor(12.0489) tensor(0.1186, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0640, grad_fn=<MeanBackward0>) tensor(12.0711) tensor(0.1026, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9857, grad_fn=<MeanBackward0>) tensor(11.9932) tensor(0.1160, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0225, grad_fn=<MeanBackward0>) tensor(12.0155) tensor(0.0968, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0291, grad_fn=<MeanBackward0>) tensor(12.0454) tensor(0.1554, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0755, grad_fn=<MeanBackward0>) tensor(12.0795) tensor(0.1178, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1127, grad_fn=<MeanBackward0>) tensor(12.0677) tensor(0.1388, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0892, grad_fn=<MeanBackward0>) tensor(12.0986) tensor(0.1063, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9989, grad_fn=<MeanBackward0>) tensor(12.0200) tensor(0.1256, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0241, grad_fn=<MeanBackward0>) tensor(12.0111) tensor(0.1640, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1068, grad_fn=<MeanBackward0>) tensor(12.1038) tensor(0.1468, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0481, grad_fn=<MeanBackward0>) tensor(12.0571) tensor(0.1160, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9884, grad_fn=<MeanBackward0>) tensor(12.0054) tensor(0.1053, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0195, grad_fn=<MeanBackward0>) tensor(11.9625) tensor(0.1708, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0438, grad_fn=<MeanBackward0>) tensor(12.0843) tensor(0.1880, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0688, grad_fn=<MeanBackward0>) tensor(12.0333) tensor(0.1653, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0356, grad_fn=<MeanBackward0>) tensor(12.0500) tensor(0.1162, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9724, grad_fn=<MeanBackward0>) tensor(11.9599) tensor(0.1534, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0053, grad_fn=<MeanBackward0>) tensor(12.0104) tensor(0.1108, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0699, grad_fn=<MeanBackward0>) tensor(12.0673) tensor(0.1104, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0177, grad_fn=<MeanBackward0>) tensor(12.0217) tensor(0.1452, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0247, grad_fn=<MeanBackward0>) tensor(12.0425) tensor(0.1149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0813, grad_fn=<MeanBackward0>) tensor(12.0762) tensor(0.1281, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9854, grad_fn=<MeanBackward0>) tensor(11.9396) tensor(0.1971, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0463, grad_fn=<MeanBackward0>) tensor(12.0572) tensor(0.1556, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0989, grad_fn=<MeanBackward0>) tensor(12.1238) tensor(0.1291, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0372, grad_fn=<MeanBackward0>) tensor(12.0545) tensor(0.1352, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0716, grad_fn=<MeanBackward0>) tensor(12.0741) tensor(0.1152, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9498, grad_fn=<MeanBackward0>) tensor(11.9268) tensor(0.1432, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0185, grad_fn=<MeanBackward0>) tensor(12.0269) tensor(0.1254, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0297, grad_fn=<MeanBackward0>) tensor(12.0191) tensor(0.1079, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1307, grad_fn=<MeanBackward0>) tensor(12.1179) tensor(0.1692, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0121, grad_fn=<MeanBackward0>) tensor(12.0217) tensor(0.1366, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0220, grad_fn=<MeanBackward0>) tensor(12.0220) tensor(0.1284, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0458, grad_fn=<MeanBackward0>) tensor(12.0624) tensor(0.1260, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0238, grad_fn=<MeanBackward0>) tensor(12.0143) tensor(0.1182, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9960, grad_fn=<MeanBackward0>) tensor(12.0019) tensor(0.1418, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0112, grad_fn=<MeanBackward0>) tensor(11.9812) tensor(0.1358, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0185, grad_fn=<MeanBackward0>) tensor(12.0242) tensor(0.0995, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0202, grad_fn=<MeanBackward0>) tensor(12.0172) tensor(0.1597, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0159, grad_fn=<MeanBackward0>) tensor(12.0056) tensor(0.1133, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0640, grad_fn=<MeanBackward0>) tensor(12.0481) tensor(0.1126, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0310, grad_fn=<MeanBackward0>) tensor(12.0272) tensor(0.1682, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9753, grad_fn=<MeanBackward0>) tensor(11.9963) tensor(0.1394, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0246, grad_fn=<MeanBackward0>) tensor(12.0342) tensor(0.1574, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9866, grad_fn=<MeanBackward0>) tensor(11.9851) tensor(0.1438, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9065, grad_fn=<MeanBackward0>) tensor(11.9044) tensor(0.1208, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9695, grad_fn=<MeanBackward0>) tensor(11.9826) tensor(0.0942, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0736, grad_fn=<MeanBackward0>) tensor(12.0929) tensor(0.1233, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0533, grad_fn=<MeanBackward0>) tensor(12.0466) tensor(0.1586, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9558, grad_fn=<MeanBackward0>) tensor(11.9480) tensor(0.1443, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9592, grad_fn=<MeanBackward0>) tensor(11.9622) tensor(0.1196, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0771, grad_fn=<MeanBackward0>) tensor(12.0878) tensor(0.1681, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0314, grad_fn=<MeanBackward0>) tensor(12.0550) tensor(0.1296, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0770, grad_fn=<MeanBackward0>) tensor(12.0779) tensor(0.1275, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0341, grad_fn=<MeanBackward0>) tensor(12.0548) tensor(0.1149, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0302, grad_fn=<MeanBackward0>) tensor(12.0107) tensor(0.1426, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0197, grad_fn=<MeanBackward0>) tensor(12.0175) tensor(0.1004, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9894, grad_fn=<MeanBackward0>) tensor(11.9857) tensor(0.1258, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0577, grad_fn=<MeanBackward0>) tensor(12.0460) tensor(0.1329, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9885, grad_fn=<MeanBackward0>) tensor(11.9818) tensor(0.1387, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9771, grad_fn=<MeanBackward0>) tensor(12.0085) tensor(0.1251, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0513, grad_fn=<MeanBackward0>) tensor(12.0112) tensor(0.1739, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9920, grad_fn=<MeanBackward0>) tensor(12.0015) tensor(0.1220, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9832, grad_fn=<MeanBackward0>) tensor(11.9911) tensor(0.1316, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9769, grad_fn=<MeanBackward0>) tensor(11.9673) tensor(0.1197, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9834, grad_fn=<MeanBackward0>) tensor(11.9753) tensor(0.1381, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0324, grad_fn=<MeanBackward0>) tensor(12.0375) tensor(0.1503, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9781, grad_fn=<MeanBackward0>) tensor(11.9458) tensor(0.1534, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0128, grad_fn=<MeanBackward0>) tensor(11.9836) tensor(0.1269, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0085, grad_fn=<MeanBackward0>) tensor(12.0047) tensor(0.1498, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0064, grad_fn=<MeanBackward0>) tensor(12.0234) tensor(0.1155, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0059, grad_fn=<MeanBackward0>) tensor(12.0029) tensor(0.1745, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0084, grad_fn=<MeanBackward0>) tensor(12.0279) tensor(0.1179, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0062, grad_fn=<MeanBackward0>) tensor(12.0286) tensor(0.1396, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0042, grad_fn=<MeanBackward0>) tensor(11.9780) tensor(0.1447, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9686, grad_fn=<MeanBackward0>) tensor(11.9919) tensor(0.1218, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0963, grad_fn=<MeanBackward0>) tensor(12.0833) tensor(0.1414, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0018, grad_fn=<MeanBackward0>) tensor(12.0074) tensor(0.1285, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0356, grad_fn=<MeanBackward0>) tensor(12.0595) tensor(0.1371, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9473, grad_fn=<MeanBackward0>) tensor(11.9386) tensor(0.1285, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0799, grad_fn=<MeanBackward0>) tensor(12.0844) tensor(0.1010, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9279, grad_fn=<MeanBackward0>) tensor(11.9356) tensor(0.1392, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9644, grad_fn=<MeanBackward0>) tensor(11.9546) tensor(0.1204, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9705, grad_fn=<MeanBackward0>) tensor(11.9719) tensor(0.1161, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1184, grad_fn=<MeanBackward0>) tensor(12.0788) tensor(0.0990, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0147, grad_fn=<MeanBackward0>) tensor(12.0038) tensor(0.1393, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0469, grad_fn=<MeanBackward0>) tensor(12.0544) tensor(0.1713, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0081, grad_fn=<MeanBackward0>) tensor(12.0450) tensor(0.1655, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9948, grad_fn=<MeanBackward0>) tensor(12.0090) tensor(0.0850, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9745, grad_fn=<MeanBackward0>) tensor(11.9667) tensor(0.1212, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0338, grad_fn=<MeanBackward0>) tensor(12.0217) tensor(0.1531, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0895, grad_fn=<MeanBackward0>) tensor(12.1116) tensor(0.1499, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9342, grad_fn=<MeanBackward0>) tensor(11.9298) tensor(0.1134, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0777, grad_fn=<MeanBackward0>) tensor(12.0793) tensor(0.1375, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0088, grad_fn=<MeanBackward0>) tensor(12.0178) tensor(0.1396, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0068, grad_fn=<MeanBackward0>) tensor(11.9917) tensor(0.1021, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0034, grad_fn=<MeanBackward0>) tensor(12.0280) tensor(0.1673, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9866, grad_fn=<MeanBackward0>) tensor(11.9730) tensor(0.1326, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0496, grad_fn=<MeanBackward0>) tensor(12.0529) tensor(0.1176, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0627, grad_fn=<MeanBackward0>) tensor(12.1020) tensor(0.1522, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0355, grad_fn=<MeanBackward0>) tensor(12.0247) tensor(0.1524, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0745, grad_fn=<MeanBackward0>) tensor(12.0963) tensor(0.0951, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0786, grad_fn=<MeanBackward0>) tensor(12.0545) tensor(0.1553, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0536, grad_fn=<MeanBackward0>) tensor(12.0497) tensor(0.1019, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0359, grad_fn=<MeanBackward0>) tensor(12.0312) tensor(0.1530, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0171, grad_fn=<MeanBackward0>) tensor(12.0061) tensor(0.1456, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9882, grad_fn=<MeanBackward0>) tensor(11.9987) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0420, grad_fn=<MeanBackward0>) tensor(12.0421) tensor(0.1226, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0447, grad_fn=<MeanBackward0>) tensor(12.0598) tensor(0.0952, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0419, grad_fn=<MeanBackward0>) tensor(12.0517) tensor(0.1454, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9867, grad_fn=<MeanBackward0>) tensor(11.9933) tensor(0.1314, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0232, grad_fn=<MeanBackward0>) tensor(12.0031) tensor(0.1126, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0353, grad_fn=<MeanBackward0>) tensor(12.0398) tensor(0.1202, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0478, grad_fn=<MeanBackward0>) tensor(12.0518) tensor(0.0945, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0143, grad_fn=<MeanBackward0>) tensor(12.0315) tensor(0.1226, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0228, grad_fn=<MeanBackward0>) tensor(12.0183) tensor(0.1584, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1436, grad_fn=<MeanBackward0>) tensor(12.1690) tensor(0.1196, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0369, grad_fn=<MeanBackward0>) tensor(12.0366) tensor(0.1405, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0621, grad_fn=<MeanBackward0>) tensor(12.0682) tensor(0.1194, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9812, grad_fn=<MeanBackward0>) tensor(11.9900) tensor(0.1105, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9328, grad_fn=<MeanBackward0>) tensor(11.9134) tensor(0.1292, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0762, grad_fn=<MeanBackward0>) tensor(12.1027) tensor(0.1423, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0079, grad_fn=<MeanBackward0>) tensor(11.9838) tensor(0.1321, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0464, grad_fn=<MeanBackward0>) tensor(12.0543) tensor(0.0981, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0137, grad_fn=<MeanBackward0>) tensor(12.0184) tensor(0.1298, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0345, grad_fn=<MeanBackward0>) tensor(12.0195) tensor(0.1215, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9891, grad_fn=<MeanBackward0>) tensor(11.9978) tensor(0.1155, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9784, grad_fn=<MeanBackward0>) tensor(11.9492) tensor(0.1420, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0849, grad_fn=<MeanBackward0>) tensor(12.0673) tensor(0.1557, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9161, grad_fn=<MeanBackward0>) tensor(11.9605) tensor(0.1040, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0786, grad_fn=<MeanBackward0>) tensor(12.0725) tensor(0.1743, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0205, grad_fn=<MeanBackward0>) tensor(12.0005) tensor(0.1485, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1021, grad_fn=<MeanBackward0>) tensor(12.1004) tensor(0.1486, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0159, grad_fn=<MeanBackward0>) tensor(12.0039) tensor(0.1413, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9759, grad_fn=<MeanBackward0>) tensor(11.9821) tensor(0.1338, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0220, grad_fn=<MeanBackward0>) tensor(12.0346) tensor(0.1930, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0118, grad_fn=<MeanBackward0>) tensor(12.0332) tensor(0.1059, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0180, grad_fn=<MeanBackward0>) tensor(12.0044) tensor(0.1259, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9837, grad_fn=<MeanBackward0>) tensor(11.9585) tensor(0.1391, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0092, grad_fn=<MeanBackward0>) tensor(12.0277) tensor(0.0974, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0621, grad_fn=<MeanBackward0>) tensor(12.0615) tensor(0.0864, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9978, grad_fn=<MeanBackward0>) tensor(12.0293) tensor(0.1539, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0404, grad_fn=<MeanBackward0>) tensor(12.0319) tensor(0.1784, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0581, grad_fn=<MeanBackward0>) tensor(12.0554) tensor(0.1227, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0089, grad_fn=<MeanBackward0>) tensor(12.0147) tensor(0.0978, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0077, grad_fn=<MeanBackward0>) tensor(12.0033) tensor(0.1272, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0251, grad_fn=<MeanBackward0>) tensor(12.0196) tensor(0.1548, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1084, grad_fn=<MeanBackward0>) tensor(12.1028) tensor(0.1714, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0391, grad_fn=<MeanBackward0>) tensor(12.0349) tensor(0.1201, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9853, grad_fn=<MeanBackward0>) tensor(11.9779) tensor(0.1697, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.0315, grad_fn=<MeanBackward0>) tensor(12.0322) tensor(0.1000, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(12.1083, grad_fn=<MeanBackward0>) tensor(12.1172) tensor(0.1075, grad_fn=<SqrtBackward0>)\n",
      "loss tensor(11.9699, grad_fn=<MeanBackward0>) tensor(11.9799) tensor(0.1378, grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_result = model_trainer.train(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.305909</td>\n",
       "      <td>1.353659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.323813</td>\n",
       "      <td>1.288336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.261861</td>\n",
       "      <td>1.239818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.329529</td>\n",
       "      <td>1.335284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.150886</td>\n",
       "      <td>1.221271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.155711</td>\n",
       "      <td>0.120527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.141257</td>\n",
       "      <td>0.189416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.139103</td>\n",
       "      <td>0.141789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.122729</td>\n",
       "      <td>0.148662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.120063</td>\n",
       "      <td>0.125013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "0    1.305909  1.353659\n",
       "1    1.323813  1.288336\n",
       "2    1.261861  1.239818\n",
       "3    1.329529  1.335284\n",
       "4    1.150886  1.221271\n",
       "..        ...       ...\n",
       "195  0.155711  0.120527\n",
       "196  0.141257  0.189416\n",
       "197  0.139103  0.141789\n",
       "198  0.122729  0.148662\n",
       "199  0.120063  0.125013\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result[1:][10:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = torch.stack([\n",
    "    kaggle_housing_dataset.val[i][0]\n",
    "    for i in range(len(kaggle_housing_dataset.val))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = torch.stack([\n",
    "    kaggle_housing_dataset.val[i][1]\n",
    "    for i in range(len(kaggle_housing_dataset.val))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y = model_trainer.model(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(\n",
    "    torch.stack([\n",
    "        torch.exp(torch.flatten(model_y.detach())),\n",
    "        torch.exp(torch.flatten(val_y))\n",
    "    ], dim = 1),\n",
    "    columns=[\"pred\", \"val\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243299.875000</td>\n",
       "      <td>254899.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110280.101562</td>\n",
       "      <td>119000.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106731.296875</td>\n",
       "      <td>124000.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149622.343750</td>\n",
       "      <td>143999.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118609.726562</td>\n",
       "      <td>106000.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>264959.531250</td>\n",
       "      <td>327999.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>122878.250000</td>\n",
       "      <td>132500.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>108696.968750</td>\n",
       "      <td>119000.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>131237.421875</td>\n",
       "      <td>129999.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>217613.703125</td>\n",
       "      <td>206299.921875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred            val\n",
       "0    243299.875000  254899.984375\n",
       "1    110280.101562  119000.046875\n",
       "2    106731.296875  124000.007812\n",
       "3    149622.343750  143999.953125\n",
       "4    118609.726562  106000.031250\n",
       "..             ...            ...\n",
       "287  264959.531250  327999.875000\n",
       "288  122878.250000  132500.046875\n",
       "289  108696.968750  119000.046875\n",
       "290  131237.421875  129999.976562\n",
       "291  217613.703125  206299.921875\n",
       "\n",
       "[292 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='pred', ylabel='val'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df.plot(kind=\"scatter\", x=\"pred\", y=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1488)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(\n",
    "    torch.flatten(model_y.detach()),\n",
    "    torch.flatten(val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = torch.stack([\n",
    "    kaggle_housing_dataset.test[i][0]\n",
    "    for i in range(len(kaggle_housing_dataset.test))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_trainer.model.forward_scaled(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_df = pd.DataFrame({\n",
    "    \"Id\": kaggle_housing_dataset.test.dataframe[\"Id\"],\n",
    "    \"SalePrice\": torch.flatten(preds).detach()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_df.to_csv(\"datasets/kaggle_housing/test_preds/20230107-v5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0cc55c9a6273ac611ac45354e806ce2ea6815ce9e9e22022522b968134159d4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
